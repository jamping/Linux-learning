搭建步骤

第1-6步是每台服务器都需要的。

1. 升级系统，在命令行运行

yum update -y

2. 关闭防火墙,swap，因为k8s需要运行多个服务在不同的服务器上通讯，需要开放多个端口，简单起见，直接把防火墙关了，不推荐在生产环境这么做。关掉swap，k8s的组件kebelet才可以正常工作。

systemctl disable firewalld
systemctl stop firewalld

firewall-cmd --zone=public --add-port={6443/tcp,10250/tcp} --permanent && firewall-cmd --reload

禁用swap文件
然后需要禁用swap文件，这是Kubernetes的强制步骤。实现它很简单，编辑/etc/fstab文件，注释掉引用swap的行，保存并重启后输入sudo swapoff -a即可。
swapoff -a

3.安装docker
yum install -y docker-ce
systemctl enable docker && systemctl start docker

4.安装kubeadm,kubelet,kubectl

cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF
setenforce 0
yum install -y kubelet kubeadm kubectl
systemctl enable kubelet && systemctl start kubelet

5.关闭selinux，因为kubelet目前支持selinux还有点问题

setenforce 0  
sed -i 's/^SELINUX=.*/SELINUX=disabled/g' /etc/sysconfig/selinux

打开/etc/sysconfig/selinux文件

vi /etc/sysconfig/selinux  

找到SELINUX那行，改为
SELINUX=disabled
保存文件

6.设置net.bridge.bridge-nf-call-iptables为1

cat << EOF > /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF

sysctl --system

7.修改节点的 hostname，因为 kubernetes 是根据 hostname 来标示各节点的。

# Master 节点
echo "192.168.72.132 k8s-master" > /etc/hostname
echo "192.168.72.132 k8s-master" >> /etc/hosts
echo "192.168.72.133 k8s-node1" >> /etc/hosts
echo "192.168.72.134 k8s-node2" >> /etc/hosts
echo "192.168.72.135 k8s-node3" >> /etc/hosts
sysctl kernel.hostname="192.168.72.132 k8s-master"

 # 不重启情况下使内核修改生效

8. 修改配置文件
cat > /etc/docker/daemon.json <<EOF
{
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2",
  "storage-opts": [
    "overlay2.override_kernel_check=true"
  ]
}
EOF

mkdir -p /etc/systemd/system/docker.service.d

# Restart Docker
systemctl daemon-reload
systemctl restart docker

vi /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
KUBELET_CGROUP_ARGS=cgroupfs

这里要特别强调一下,一定要修改kubelet 和 docker 的驱动为cgroupfs,修改后 reload 一下服务
systemctl daemon-reload

9.初始化master，在master的节点上运行

由于网络原因，我们需要提前拉取k8s初始化需要用到的Images，并添加对应的k8s.gcr.io标签
或者使用如下命令

kubeadm config images list |sed -e 's/^/docker pull /g' -e 's#k8s.gcr.io#docker.io/mirrorgooglecontainers#g' |sh -x
docker images |grep mirrorgooglecontainers |awk '{print "docker tag ",$1":"$2,$1":"$2}' |sed -e 's#mirrorgooglecontainers#k8s.gcr.io#2' |sh -x
docker images |grep mirrorgooglecontainers |awk '{print "docker rmi ", $1":"$2}' |sh -x
docker pull coredns/coredns:1.3.1
docker tag coredns/coredns:1.3.1 k8s.gcr.io/coredns:1.3.1
docker rmi coredns/coredns:1.3.1

Master节点就是运行着控制组件的机器，包括etcd(集群数据库)和API服务(kubectl CLI通讯服务)。
初始化master节点, 只需随便在一台装过kubeadm的机器上运行如下命令

kubeadm init --kubernetes-version=v1.14.1  --pod-network-cidr=192.168.0.0/16

把上面输出的最后一行 kubeadm join复制保存下来，后面在node节点加入到集群中需要用到
运行下面的命令初始化kebectl配置文件

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 192.168.72.132:6443 --token w9wgvl.t2yns0btggu2lk9z \
    --discovery-token-ca-cert-hash sha256:2ada98de317369066ebffe7085c3c089470047f2b04aaa311347caa0fef0876a 

10.安装网络插件，以使pod能相互通讯，这里我们安装的是Weave Net在master节点运行

kubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\n')"

运行以下命令检查kube-dns pod 已经运行，一般需要几十秒

kubectl get pods --all-namespaces

如果输出中有名字以kube-dns的pod状态是Running，说明网络插件已经正常工作，然后就可以把node节点加入到集群

11. 隔离主节点

默认情况下，出于安全的考虑，并不会在主节点上运行pod，如果你想在主节点上运行pod，比如：运行一个单机版的kubernetes集群时，可运行下面的命令：

kubectl taint nodes --all node-role.kubernetes.io/master-

(可选)在非主节点上管理集群
为了可以在其他电脑上使用kubectl来管理你的集群，可以从主节点上复制管理员 的kubeconfig文件到你的电脑上：

scp root@<master ip>:/etc/kubernetes/admin.conf .
kubectl --kubeconfig ./admin.conf get nodes

(可选)映射API服务到本地
如果你想从集群外部连接到API服务，可以使用工具kubectl proxy:

scp root@<master ip>:/etc/kubernetes/admin.conf .
kubectl --kubeconfig ./admin.conf proxy

这样就可以在本地这样 http://localhost:8001/api/v1 访问到API服务了。

(可选)部署一个微服务
现在可以测试你新搭建的集群了，Sock Shop就是一个微服务的样本，它体现了在Kubernetes里如何运行和连接一系列的服务。想了解更多关于微服务的内容，请查看GitHub README。

kubectl create namespace sock-shop
kubectl apply -n sock-shop -f "https://github.com/microservices-demo/microservices-demo/blob/master/deploy/kubernetes/complete-demo.yaml?raw=true"

可以通过以下命令来查看前端服务是否有开放对应的端口：
kubectl -n sock-shop get svc front-end

可能需要几分钟时间来下载和启用所有的容器，通过kubectl get pods -n sock-shop来获取服务的状态。

卸载socks shop, 只需要在主节点上运行:
kubectl delete namespace sock-shop

卸载集群
想要撤销kubeadm做的事，首先要排除节点，并确保在关闭节点之前要清空节点。
在主节点上运行：

kubectl drain <node name> --delete-local-data --force --ignore-daemonsets
kubectl delete node <node name>

然后在需要移除的节点上，重置kubeadm的安装状态：

kubeadm reset

如果你想重新配置集群，只需运行kubeadm init或者kubeadm join并使用所需的参数即可。

12. 安装kubernates-dashboard

1)生成证书

openssl req -newkey rsa:4096 -nodes -sha256 -keyout ca.key -x509 -days 365 -out ca.crt
openssl req -newkey rsa:4096 -nodes -sha256 -keyout weishuichao.key -out weishuichao.csr
openssl x509 -req -in weishuichao.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out weishuichao.crt

2)导入证书到kube-system

kubectl create secret generic kubernetes-dashboard-certs --from-file=/data/cert -n kube-system

3)创建kubernetes-dashboard.yaml

kubectl apply -f /data/k8s/kubernetes-dashboard.yaml

配置在官网的基础上需要加上下面配置ClusterRoleBinding，用以配置权限，这样通过token登陆进去才不至于没有权限

# ------------------- Dashboard ClusterRoleBinding ------------------- #

kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
name: kubernetes-dashboard
subjects:
- kind: ServiceAccount
name: kubernetes-dashboard
namespace: kube-system
roleRef:
kind: ClusterRole
name: cluster-admin
apiGroup: rbac.authorization.k8s.io

kubernetes采用暴露端口的方式使用，增加一下配置

4) 获取kube-system 的secret

kubectl -n kube-system get secret

5) 查看token,这个token 是用于登陆使用的

kubectl -n kube-system describe secret kubernetes-dashboard-token-2qmtr

6) 访问dashboard

https://192.168.2.117:31000 输入令牌，进入dashboard主页

13. 建立机器互信

1) 在每台服务器需要建立主机互信的用户名执行以下命令生成公钥/密钥，默认回车即可

$ ssh-keygen -t rsa

Generating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa):Created directory '/root/.ssh'.Enter passphrase (empty for no passphrase):Enter same passphrase again:Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:0c:1f:76:aa:80:b2:2f:b9:9a:6a:48:96:9d:8f:a1:cc root@cctvyyycns04The key's randomart image is:+--[ RSA 2048]----+| || || . o . || . = + ||. + o S || * + . . ||B.. + . ||+E . . ||Oo. |+-----------------+

2) 互传公钥，第一次需要输入密码，之后就OK了

$ ssh-copy-id -i /root/.ssh/id_rsa.pub root@192.168.0.110

可以看到是在.ssh/下生成了个authorized_keys的文件，记录了能登陆这台服务器的其他服务器的公钥

3) 测试是否能登陆

$ ssh 192.168.0.110

14. 生成join token

kubeadm token create --print-join-command

把Node加入到master中去

kubeadm join 192.168.0.117:6443 --token c8jsl8.2noprwx5ljvezyyb --discovery-token-ca-cert-hash sha256:084277f92c715524cc8e061411577b37f41cdd74da2b245973161af461eb9d9d

15、kubeadm.yaml

apiVersion: kubeadm.k8s.io/v1beta1
kind: ClusterConfiguration
controllerManager:
    extraArgs:
        horizontal-pod-autoscaler-use-rest-clients: "true"
        horizontal-pod-autoscaler-sync-period: "10s"
        node-monitor-grace-period: "10s"
apiServer:
    extraArgs:
        runtime-config: "api/all=true"
kubernetesVersion: "stable-1.14"


kubeadm init --config kubeadm

16、PodPreset

若创建PodPreset对象不成功，一般是没有开户创建PodPreset对象权限

vi /etc/kubernetes/manifests/kube-apiserver.yaml 
在spec.containers.command:添加如下内容

 - --runtime-config=api/all=true,settings.k8s.io/v1alpha1=true
 - --enable-admission-plugins=PodPreset